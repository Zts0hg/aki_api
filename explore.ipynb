{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "import hashlib\n",
    "import time\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import sys\n",
    "from config import japanese_grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import text_to_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kanji_with_kana_pattern = re.compile(\n",
    "    r\"\\s*(?P<kanji>[\\u4E00-\\u9FFF]) (?P<kana>[\\u3040-\\u309F]+)\\s*\"\n",
    ")\n",
    "\n",
    "\n",
    "def transform_content_to_ruby_rich_text(content, pattern=None):\n",
    "    if pattern is None:\n",
    "        pattern = kanji_with_kana_pattern\n",
    "\n",
    "    return pattern.sub(r\"<ruby>\\1<rt>\\2</rt></ruby>\", content)\n",
    "\n",
    "\n",
    "def split_kanji_and_its_kana(content, pattern=None):\n",
    "    if pattern is None:\n",
    "        pattern = kanji_with_kana_pattern\n",
    "\n",
    "    return kanji_with_kana_pattern.sub(r\"\\1\", content), kanji_with_kana_pattern.sub(\n",
    "        r\"\\2\", content\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = japanese_grammar.book_folder / \"记单词，一定要学的130个日语词根-_张铭_-_Z-Library_.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kanji_with_kana_pattern = re.compile(\n",
    "    r\"(?P<kanji>[\\u4E00-\\u9FFF])(?P<kana>[\\u3040-\\u309F]+)(?:\\s|$)\"\n",
    ")\n",
    "content = \"\"\"\n",
    "▶ あかい「赤い」 ②⓪（形）：红色的\n",
    "\n",
    "解 古代日本人不区分“红”和“亮”两个概念，因为明亮的太阳光和火光都偏红色。\n",
    "\n",
    "例 赤あか い花はな が咲さ いている。/红色的花开了。\n",
    "\"\"\"\n",
    "\n",
    "print(transform_content_to_ruby_rich_text(content, pattern=kanji_with_kana_pattern))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kana_meaning_pattern = re.compile(r\"^\\d{2,}\\s\")\n",
    "example_pattern = re.compile(r\"^▶\")\n",
    "\n",
    "result = []\n",
    "kanji_with_kana_pattern = re.compile(\n",
    "    r\"(?P<kanji>[\\u4E00-\\u9FFF]+)(?P<kana>[\\u3040-\\u309F]+)(?:\\s|$)\"\n",
    ")\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as fp:\n",
    "    current_kana = \"\"\n",
    "    current_meaning_item = \"\"\n",
    "    current_meanning_explain = []\n",
    "    current_example = \"\"\n",
    "    current_example_explain = []\n",
    "    within_example_part = False\n",
    "\n",
    "    lines = fp.readlines()\n",
    "    last_line = \"\"\n",
    "    for line in lines:\n",
    "        content = line.strip()\n",
    "        if not content:\n",
    "            continue\n",
    "\n",
    "        if current_kana and content.startswith(\"第二章\"):\n",
    "            break\n",
    "\n",
    "        # 假名\n",
    "        if len(content) == 1:\n",
    "            current_kana = content\n",
    "            current_meaning_item = \"\"\n",
    "            current_meanning_explain = []\n",
    "            current_example = \"\"\n",
    "            current_example_explain = []\n",
    "            within_example_part = False\n",
    "            continue\n",
    "\n",
    "        # 假名词根含义\n",
    "        if current_kana and kana_meaning_pattern.match(content):\n",
    "            current_meaning_item = content\n",
    "            within_example_part = False\n",
    "            item_idx = content.split()[0]\n",
    "            continue\n",
    "\n",
    "        # 词根含义举例\n",
    "        if current_kana and example_pattern.match(content):\n",
    "            within_example_part = True\n",
    "            if current_example:\n",
    "                result.append(\n",
    "                    {\n",
    "                        \"kana\": current_kana,\n",
    "                        \"meaning\": current_meaning_item,\n",
    "                        \"explain\": \"<br>\".join(current_meanning_explain),\n",
    "                        \"example\": current_example,\n",
    "                        \"example_explain\": \"<br>\".join(\n",
    "                            [\n",
    "                                transform_content_to_ruby_rich_text(\n",
    "                                    content, pattern=kanji_with_kana_pattern\n",
    "                                )\n",
    "                                for content in current_example_explain\n",
    "                            ]\n",
    "                        ),\n",
    "                    }\n",
    "                )\n",
    "\n",
    "            current_example = content\n",
    "            current_example_explain = []\n",
    "            continue\n",
    "\n",
    "        # 词根举例 解释\n",
    "        if current_example:\n",
    "            current_example_explain.append(content)\n",
    "            continue\n",
    "\n",
    "        # 假名词根 解释 \n",
    "        if current_kana and not within_example_part:\n",
    "            current_meanning_explain.append(content)\n",
    "\n",
    "        last_line = content\n",
    "\n",
    "\n",
    "\n",
    "if current_example_explain:\n",
    "    result.append(\n",
    "        {\n",
    "            \"kana\": current_kana,\n",
    "            \"meaning\": current_meaning_item,\n",
    "            \"explain\": \"<br>\".join(current_meanning_explain),\n",
    "            \"example\": current_example,\n",
    "            \"example_explain\": \"<br>\".join(\n",
    "                [\n",
    "                    transform_content_to_ruby_rich_text(\n",
    "                        content, pattern=kanji_with_kana_pattern\n",
    "                    )\n",
    "                    for content in current_example_explain\n",
    "                ]\n",
    "            ),\n",
    "        }\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(result).fillna(\"\")\n",
    "print(df.shape)\n",
    "df.to_csv(\"word_roots.csv\", index=False)\n",
    "df.to_csv(\"word_roots_anki.csv\", index=False, header=False)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_kana = \"\"\n",
    "last_meaning = \"\"\n",
    "for index in df.index:\n",
    "    detail = df.loc[index].to_dict()\n",
    "    if detail[\"kana\"] != last_kana:\n",
    "        print(\"=\" * 32)\n",
    "        print(detail[\"kana\"])\n",
    "    if detail[\"meaning\"] != last_meaning:\n",
    "        print()\n",
    "        print(detail[\"meaning\"])\n",
    "        print(detail[\"explain\"])\n",
    "\n",
    "    example_explain = detail[\"example_explain\"].split(\"<br>\")[0]\n",
    "    example_explain = \"\" if example_explain[0] != \"解\" else \" \".join(example_explain.split()[1:])\n",
    "    print(detail[\"example\"])\n",
    "    if example_explain:\n",
    "        print(example_explain)\n",
    "\n",
    "    last_kana = detail[\"kana\"]\n",
    "    last_meaning = detail[\"meaning\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_type_answer = []\n",
    "\n",
    "kana_pattern = re.compile(r\"(?<=^▶ )([\\u3040-\\u309F]+)(?=「)\")\n",
    "meaning_pattern = re.compile(r\"(?<=：)(.+)$\")\n",
    "content_pattern = re.compile(r\"^▶ ([\\u3040-\\u309F]+)(?:「(.+)」|\\s?」)?\\s*([⓪\\u2460-\\u2470]+)(（[·、\\u4E00-\\u9FFFサ]+）)：(.*)$\")\n",
    "\"\"\"\n",
    "▶ あかい「赤い」 ②⓪（形）：红色的\n",
    "▶ あける「明ける」 ⓪（自一）：天亮了；过年\n",
    "▶ {{c1::あかい}}「赤い」 ②⓪（形）：{{c2::红色的}}\n",
    "\"\"\"\n",
    "for record in result:\n",
    "    result_type_answer.append({\n",
    "        \"word\": content_pattern.sub(r\"{{c1::\\1}}<br>\\2 \\3 \\4<br>{{c2::\\5}}\", record[\"example\"]),\n",
    "        \"word_explain\": record[\"example_explain\"],\n",
    "        \"kana_meaning\": record[\"meaning\"],\n",
    "        \"kana_meaning_explain\": record[\"explain\"],\n",
    "    })\n",
    "\n",
    "df_res = pd.DataFrame(result_type_answer, dtype=str).fillna(\"\")\n",
    "df_res.to_csv(\"word_roots(type_answer_anki).csv\", index=False, header=False)\n",
    "print(df_res.shape)\n",
    "df_res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_md5(content):\n",
    "    content = content.encode(\"utf-8\")\n",
    "    md5_hash = hashlib.md5()\n",
    "    md5_hash.update(content)\n",
    "    return md5_hash.hexdigest()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "sentence_content_pattern = re.compile(r'([\\u2460-\\u2470])\\s*')\n",
    "invalid_line_pattern = re.compile(r'^[\\d\\s]+$')\n",
    "\n",
    "example_sentences = []\n",
    "groups = []\n",
    "with open(\"CS_Word_20240405_22.25.17.txt\", \"r\", encoding=\"utf-8\") as fp:\n",
    "    matched = False\n",
    "    sentence = None\n",
    "    last_line = \"\"\n",
    "    for line in fp.readlines():\n",
    "        line = line.strip()\n",
    "        if len(line) < 3 or invalid_line_pattern.match(line.strip()):\n",
    "            continue\n",
    "\n",
    "        if matched == True and last_line[-1] != \"。\":\n",
    "            sentence[\"content\"] += line\n",
    "            last_line = line\n",
    "            continue\n",
    "\n",
    "        if sentence_content_pattern.match(line.strip()):\n",
    "            matched = True\n",
    "            sentence = {\"content\": sentence_content_pattern.sub(r\"\\1 \", line)}\n",
    "        else:\n",
    "            if matched:\n",
    "                sentence[\"hiragana\"] = \"\"\n",
    "                sentence[\"meaning\"] = line\n",
    "                if sentence[\"meaning\"][1] == \" \":\n",
    "                    sentence[\"meaning\"] = sentence[\"meaning\"][2:]\n",
    "\n",
    "                if sentence[\"meaning\"][0] == \"囉\":\n",
    "                    sentence[\"meaning\"] = sentence[\"meaning\"][1:]\n",
    "\n",
    "                if sentence[\"content\"][0] == \"①\" and groups:\n",
    "                    example_sentences.append(groups)\n",
    "                    groups = []\n",
    "\n",
    "                groups.append(sentence)\n",
    "            matched = False\n",
    "        last_line = line\n",
    "\n",
    "if groups:\n",
    "    example_sentences.append(groups)\n",
    "\n",
    "print(example_sentences[1])\n",
    "with open(\"example_sentences.json\", \"w\", encoding=\"utf-8\") as fp:\n",
    "    fp.write(json.dumps(example_sentences, ensure_ascii=False, indent=4))\n",
    "    # pd.DataFrame(example_sentences, dtype=str).fillna(\"\").to_json(fp, orient=\"records\", force_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_json(\"grammar_pd.json\", dtype=str)\n",
    "with open(\"grammar.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.loads(f.read())\n",
    "    df = pd.DataFrame(data)\n",
    "df.head()\n",
    "detail = df.loc[0].to_dict()\n",
    "print(type(detail[\"example\"]))\n",
    "print(detail[\"example\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from grammar_enumeration import grammars, df_grammars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grammars.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grammars.hiragana.str.replace(r\"[（）()\\s()]\", \"\").str.contains(r'なしに')[23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword = \"なくして(は)\"\n",
    "df = df_grammars\n",
    "df[df.content.str.replace(r\"[（）()\\s()]\", \"\").str.contains(keyword)\n",
    "                    | df.hiragana.str.replace(r\"[（）()\\s()]\", \"\").str.contains(keyword)\n",
    "                    | df.chinese_meaning.str.contains(keyword) | (df.source == keyword)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"其中N1级别201个，N2级别150个，N3级别140个，N4级别130个，N5级别120个。\"\n",
    "\n",
    "import json\n",
    "import re\n",
    "\n",
    "level_pattern = re.compile(r\"^N([1-5])文法\")\n",
    "unit_pattern = re.compile(r\"^第(\\d+)单元(.*)\")\n",
    "grammar_start_pattern = re.compile(r\"^\\d+\\. \")\n",
    "seq_pattern = re.compile(r\"^（\\d+）\")\n",
    "from collections import defaultdict\n",
    "\n",
    "lines = []\n",
    "part_keywords = {'接続': 391, '説明': 401, '例文': 910, '注意': 774, '接续': 308, '说明': 515, '读法': 4, '例词': 2, '补充': 1}\n",
    "level = 0\n",
    "current_grammar = \"\"\n",
    "current_part = \"\"\n",
    "current_seq = \"\"\n",
    "output = False\n",
    "# with open(\"日语蓝宝书.txt\", \"r\", encoding=\"utf-8\") as fp:\n",
    "# for idx, line in enumerate(fp.readlines()):\n",
    "content = \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "89. ～とて\n",
    "\n",
    "\n",
    "（1）\n",
    "\n",
    "接続\n",
    "\n",
    "名＋とて\n",
    "\n",
    "説明\n",
    "\n",
    "表示假定条件的逆接，“即使……也不例外”“即使是……也……”“甚至……”“就连……”。\n",
    "\n",
    "例文\n",
    "\n",
    "△常に冷静な彼とて やはり人間だから、感情的になってしまうこともあるのだろう。 【2009年12月真题】/尽管他平时很冷静，但是也有情绪化的时候吧 。\n",
    "\n",
    "△最近の電気製品は機能が多すぎる。開発者たちとて すべての機能が必要とは思わないのではないか。 【2007年真题】/最近的电器功能实在太多，就算是开发商也未必会认为所有的功能都有必要吧 。\n",
    "\n",
    "△私とて 試合に負けたことに悔しい。 /输掉了比赛，我也很懊恼 。\n",
    "\n",
    "注意\n",
    "\n",
    "①前面主要接续人名。\n",
    "\n",
    "②意思与「～としても」 相同，但「～とて」 是比较生硬的表达方式。\n",
    "\n",
    "（2）\n",
    "\n",
    "接続\n",
    "\n",
    "名＋だ/動た形＋とて\n",
    "\n",
    "説明\n",
    "\n",
    "表示假定条件的逆接，无论前项怎样，后项的原则都是一样的。“即使……也……”“即便……也……”“就算……也……”。\n",
    "\n",
    "例文\n",
    "\n",
    "△たとえ病気だとて 試験に欠席してはいけない。 /就算生病了也不能缺考 。\n",
    "\n",
    "△いくら 頼 たの んだとて 、できないことはできない。 /再怎么拜托，不能做的事情就是不能做 。\n",
    "\n",
    "△どんなに後悔したとて 、過ぎたことは今さらどうしようもない。 /就算再怎么后悔，对于已经过去的事情也没有办法 。\n",
    "\n",
    "注意\n",
    "\n",
    "常与「たとえ」 「どんなに」 「いくら」 等词一起使用。\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "grammars = {}\n",
    "for _ in range(1):\n",
    "    for idx, line in enumerate(content.split(\"\\n\")):\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "\n",
    "        if res := level_pattern.findall(line):\n",
    "            level = int(res[0])\n",
    "            # print(f\"Current Level: {level}\")\n",
    "            continue\n",
    "\n",
    "        if res := unit_pattern.findall(line):\n",
    "            # print(f\"Current Unit: {res[0][0]}.{res[0][1]}\")\n",
    "            continue\n",
    "\n",
    "        if grammar_start_pattern.match(line):\n",
    "            print(f\"Current Grammar: {line}\")\n",
    "            current_grammar = line\n",
    "            grammars[current_grammar] = {}\n",
    "            # current_part = \"\"\n",
    "            # current_seq = \"\"\n",
    "            continue\n",
    "\n",
    "        if seq_pattern.match(line):\n",
    "            # print(f\"Current Seq: {line}\")\n",
    "            current_seq = line\n",
    "            continue\n",
    "\n",
    "        lines.append(line)\n",
    "\n",
    "        if len(line) < 5 and line[:2] in part_keywords:\n",
    "            current_part = line[:2]\n",
    "            if current_part == \"例文\":\n",
    "                grammars[current_grammar][current_part] = []\n",
    "            else:\n",
    "                grammars[current_grammar][current_part] = \"\"\n",
    "            continue\n",
    "\n",
    "        if current_part == \"例文\":\n",
    "            grammars[current_grammar][current_part].append(line)\n",
    "        else:\n",
    "            grammars[current_grammar][current_part] += line + \"\\n\"\n",
    "\n",
    "print(json.dumps(grammars, ensure_ascii=False, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"其中N1级别201个，N2级别150个，N3级别140个，N4级别130个，N5级别120个。\"\n",
    "\n",
    "import json\n",
    "import re\n",
    "\n",
    "content = \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "89. ～とて\n",
    "\n",
    "\n",
    "（1）\n",
    "\n",
    "接続\n",
    "\n",
    "名＋とて\n",
    "\n",
    "説明\n",
    "\n",
    "表示假定条件的逆接，“即使……也不例外”“即使是……也……”“甚至……”“就连……”。\n",
    "\n",
    "例文\n",
    "\n",
    "△常に冷静な彼とて やはり人間だから、感情的になってしまうこともあるのだろう。 【2009年12月真题】/尽管他平时很冷静，但是也有情绪化的时候吧 。\n",
    "\n",
    "△最近の電気製品は機能が多すぎる。開発者たちとて すべての機能が必要とは思わないのではないか。 【2007年真题】/最近的电器功能实在太多，就算是开发商也未必会认为所有的功能都有必要吧 。\n",
    "\n",
    "△私とて 試合に負けたことに悔しい。 /输掉了比赛，我也很懊恼 。\n",
    "\n",
    "注意\n",
    "\n",
    "①前面主要接续人名。\n",
    "\n",
    "②意思与「～としても」 相同，但「～とて」 是比较生硬的表达方式。\n",
    "\n",
    "（2）\n",
    "\n",
    "接続\n",
    "\n",
    "名＋だ/動た形＋とて\n",
    "\n",
    "説明\n",
    "\n",
    "表示假定条件的逆接，无论前项怎样，后项的原则都是一样的。“即使……也……”“即便……也……”“就算……也……”。\n",
    "\n",
    "例文\n",
    "\n",
    "△たとえ病気だとて 試験に欠席してはいけない。 /就算生病了也不能缺考 。\n",
    "\n",
    "△いくら 頼 たの んだとて 、できないことはできない。 /再怎么拜托，不能做的事情就是不能做 。\n",
    "\n",
    "△どんなに後悔したとて 、過ぎたことは今さらどうしようもない。 /就算再怎么后悔，对于已经过去的事情也没有办法 。\n",
    "\n",
    "注意\n",
    "\n",
    "常与「たとえ」 「どんなに」 「いくら」 等词一起使用。\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "level_pattern = re.compile(r\"^N([1-5])文法\")\n",
    "unit_pattern = re.compile(r\"^第(\\d+)单元(.*)\")\n",
    "grammar_start_pattern = re.compile(r\"^\\d+\\. \")\n",
    "seq_pattern = re.compile(r\"^（\\d+）\")\n",
    "\n",
    "\n",
    "def get_japanese_sequence_sign(number):\n",
    "    number = int(number)\n",
    "    if number <= 0:\n",
    "        return \"⓪\"\n",
    "\n",
    "    return chr(ord(\"\\u2460\") + number - 1)\n",
    "\n",
    "\n",
    "def extract_grammars(content):\n",
    "    grammars = {}\n",
    "    lines = []\n",
    "    part_keywords = {'接続': 391, '説明': 401, '例文': 910, '注意': 774, '接续': 308, '说明': 515, '读法': 4, '例词': 2, '补充': 1}\n",
    "    keyword_mapping = {\n",
    "        '接続': \"接续\",\n",
    "        '説明': \"说明\",\n",
    "        '读法': \"说明\",\n",
    "        '例词': \"说明\",\n",
    "        '补充': \"注意\",\n",
    "    }\n",
    "    level = 0\n",
    "    current_grammar = \"\"\n",
    "    current_part = \"\"\n",
    "    current_seq = \"\"\n",
    "    for idx, line in enumerate(content.split(\"\\n\")):\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "\n",
    "        line = line.replace(\"真题】\", \"JLPT】\")\n",
    "        if res := level_pattern.findall(line):\n",
    "            level = int(res[0])\n",
    "            # print(f\"Current Level: {level}\")\n",
    "            continue\n",
    "\n",
    "        if res := unit_pattern.findall(line):\n",
    "            # print(f\"Current Unit: {res[0][0]}.{res[0][1]}\")\n",
    "            continue\n",
    "\n",
    "        if grammar_start_pattern.match(line):\n",
    "            # print(f\"Current Grammar: {line}\")\n",
    "            current_grammar = line\n",
    "            grammars[current_grammar] = {}\n",
    "            grammars[current_grammar][\"level\"] = level\n",
    "            # current_part = \"\"\n",
    "            # current_seq = \"\"\n",
    "            continue\n",
    "\n",
    "        if seq_pattern.match(line):\n",
    "            print(f\"Current Seq: {line}\")\n",
    "            current_seq = line\n",
    "            continue\n",
    "\n",
    "        lines.append(line)\n",
    "\n",
    "        if len(line) < 5 and line[:2] in part_keywords:\n",
    "            current_part = line[:2]\n",
    "            current_part = keyword_mapping.get(current_part, current_part)\n",
    "            index = f\"{get_japanese_sequence_sign(line[2])} \" if len(line) > 2 else \"\"\n",
    "            if current_part not in grammars[current_grammar]:\n",
    "                if current_part == \"例文\":\n",
    "                    grammars[current_grammar][current_part] = []\n",
    "                else:\n",
    "                    grammars[current_grammar][current_part] = \"\"\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            if current_part == \"例文\":\n",
    "                grammars[current_grammar][current_part].append(line)\n",
    "            else:\n",
    "                grammars[current_grammar][current_part] += index + line + \"\\n\"\n",
    "                index = \"\"\n",
    "        except Exception:\n",
    "            print((idx, line))\n",
    "            raise\n",
    "\n",
    "    return grammars\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dumps(\"⓪①②③\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chr(ord(\"\\u2460\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kanji_with_kana_pattern = re.compile(r\"(?P<kanji>[\\u4E00-\\u9FFF]) (?P<kana>[\\u3040-\\u309F]+) \")\n",
    "content = \"中 なか 川 がわ 先 せん 生 せい 「あ、 山 やま 口 ぐち さん。 偶 ぐう 然 ぜん ですね。」\"\n",
    "content = \"辞书形 ⇒ 尊他语(辞书形)\"\n",
    "content = \"做 | する ⇒ なさる\"\n",
    "content = \"84. ～ 中 ちゅう/じゅう\"\n",
    "print(kanji_with_kana_pattern.findall(content))\n",
    "kanji_with_kana_pattern.sub(r\"<ruby>\\1<rt>\\2</rt></ruby>\", content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "content = \"△お 客 きゃく 様 さま 、このお 皿 さら をさげてもよろしいでしょうか 。 /客人您好，这个盘子我可以撤下去了吗 ？\"\n",
    "print(transform_content_to_ruby_rich_text(content))\n",
    "\n",
    "\n",
    "print(split_kanji_and_its_kana(content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Seq: （1）～いかんで/いかんでは/いかんによっては\n",
      "Current Seq: （2）～いかんにかかっている/いかんだ\n",
      "Current Seq: （1）いざ～となると\n",
      "Current Seq: （2）いざとなると/いざとなれば/いざとなったら\n",
      "Current Seq: （1）\n",
      "Current Seq: （2）\n",
      "Current Seq: （1）～といったらありはしない/といったらありゃしない/といったらない\n",
      "Current Seq: （2）～ったらない/ったらありゃしない\n",
      "Current Seq: （1）\n",
      "Current Seq: （2）\n",
      "Current Seq: （1）～なしには/なしでは\n",
      "Current Seq: （2）～なしに\n",
      "Current Seq: （1）\n",
      "Current Seq: （2）\n",
      "Current Seq: （1）～に至って/に至る\n",
      "Current Seq: （2）～に至っては\n",
      "Current Seq: （3）～に至っても\n",
      "Current Seq: （1）～には及ばない\n",
      "Current Seq: （2）～に（は）及ばない\n",
      "Current Seq: （1）にして\n",
      "Current Seq: （2）AにしてB\n",
      "Current Seq: （3）～にしてはじめて\n",
      "Current Seq: （4）～にして～（ない）\n",
      "Current Seq: （1）～にたえる\n",
      "Current Seq: （2）～にたえない\n",
      "Current Seq: （1）～べからず\n",
      "Current Seq: （2）～べからざる\n",
      "Current Seq: （1）～をもって/をもちまして\n",
      "Current Seq: （2）～をもって\n",
      "Current Seq: （1）～限り（は）\n",
      "Current Seq: （2）～限りでは\n",
      "Current Seq: （1）～次第\n",
      "Current Seq: （2）～次第だ/次第で\n",
      "Current Seq: （1）～とか/とかいう\n",
      "Current Seq: （2）～とかいうことだ/とかいう 話 はなし だ\n",
      "Current Seq: （3）～とかで\n",
      "Current Seq: （1）～ところを\n",
      "Current Seq: （2）～ところを 見 み ると\n",
      "Current Seq: （1）～に限って/に限り\n",
      "Current Seq: （2）～に 限 かぎ って\n",
      "Current Seq: （1）～のもとで/のもとに\n",
      "Current Seq: （22）～の 名 な のもとに\n",
      "Current Seq: （1）主格助词：が、の\n",
      "Current Seq: （2）宾格助词：が、を\n",
      "Current Seq: （3）领格助词：が、の\n",
      "Current Seq: （4）补格助词：から、で、と、に、へ、まで、より、を\n",
      "{'id': 1, 'content': '～あっての', 'hiragana': '', 'meaning': '表示条件，“正因为有了A，才有B的存在”。', 'usage': '名A＋（が）あっての＋名B', 'example': [{'content': '① 山田監督は私の<ruby>恩<rt>おん</rt></ruby><ruby>人<rt>じん</rt></ruby>です。今の私があるのも監督あっての ことです。 ', 'tag': '【2010年12月JLPT】', 'meaning': '山田教练是我的恩人。正是因为有教练的帮助，才有今天的我 。'}, {'content': '② つらい治療に耐え、病気を<ruby>克<rt>こく</rt></ruby><ruby>服<rt>ふく</rt></ruby>することができたのは、家族の励ましがあっての ことだ。 ', 'tag': '【2007年JLPT】', 'meaning': '我之所以能够克服治疗的痛苦，战胜病魔，正是因为有家人的支持和鼓励 。'}, {'content': '③ こうして私たちが<ruby>商<rt>しょう</rt></ruby><ruby>売<rt>ばい</rt></ruby>を続けられるのも、お客様あっての ものと感謝しております。 ', 'tag': '【2005年JLPT】', 'meaning': '正因为有客户的支持才能持续经营下去，对此我们深表感谢 。'}], 'remark': '①前项和后项是不同的名词。强调前项的助词「が」 可以省略，后项也会以「もの」 「こと」 的形式出现，如「～あってのことだ」 「～あってのものだ」 。\\n②意思与「～があるからこそ」 相同，“正因为……才……”。\\n③固定用法：「命あっての<ruby>物<rt>もの</rt></ruby><ruby>種<rt>だね</rt></ruby>」 /有了生命才会有一切；留得青山在，不怕没柴烧。', 'source': 'S2N1-N5', 'japanese_meaning': '', 'chinese_meaning': '表示条件，“正因为有了A，才有B的存在”。', 'level': 1}\n"
     ]
    }
   ],
   "source": [
    "def merge_example_sentences(sentences):\n",
    "    new_sentences = []\n",
    "    for sentence in sentences:\n",
    "        if not sentence.startswith(\"△\"):\n",
    "            new_sentences[-1] += \"\\n\" + sentence\n",
    "        elif sentence.startswith(\"△B\"):\n",
    "            new_sentences[-1] += \"\\n  \" + sentence[1:]\n",
    "        else:\n",
    "            new_sentences.append(sentence)\n",
    "\n",
    "    return new_sentences\n",
    "\n",
    "\n",
    "with open(japanese_grammar.book_folder / \"日语蓝宝书.txt\", \"r\", encoding=\"utf-8\") as fp:\n",
    "    content = fp.read()\n",
    "\n",
    "empty_usage = []\n",
    "grammars = extract_grammars(content)\n",
    "# print(json.dumps(grammars, ensure_ascii=False, indent=4))\n",
    "part_keywords = {'接続': 391, '説明': 401, '例文': 910, '注意': 774, '接续': 308, '说明': 515, '读法': 4, '例词': 2, '补充': 1}\n",
    "example_sentence_pattern = re.compile(r\"^([^/]+?)(【\\d+年(?:\\d+月)?JLPT】)?/(.*)$\", re.DOTALL)\n",
    "header_pattern = re.compile(r\"^△\\s*\")\n",
    "formatted_grammars = []\n",
    "for idx, (grammar, detail) in enumerate(grammars.items()):\n",
    "    try:\n",
    "        content = grammar_start_pattern.sub(\"\", grammar)\n",
    "        hiragana = \"\"\n",
    "        rich_text = transform_content_to_ruby_rich_text(content)\n",
    "        if rich_text != content:\n",
    "            content, hiragana = split_kanji_and_its_kana(content)\n",
    "\n",
    "        example_sentences = detail.get(\"例文\") or []\n",
    "        example_sentences = merge_example_sentences(example_sentences)\n",
    "        formated_exmpale_sentences = []\n",
    "\n",
    "        for sentence_seq, sentence in enumerate(example_sentences):\n",
    "            sentence_content, tag, meaning = example_sentence_pattern.findall(sentence)[0]\n",
    "            sentence_content = header_pattern.sub(\"\", sentence_content)\n",
    "            sentence_content = f\"{get_japanese_sequence_sign(sentence_seq+1)} {sentence_content}\"\n",
    "\n",
    "            sentence_content = transform_content_to_ruby_rich_text(sentence_content)\n",
    "            formated_exmpale_sentences.append({\"content\": sentence_content, \"tag\": tag, \"meaning\": meaning})\n",
    "\n",
    "        # example_sentences = [{\"content\": sentence} for sentence in map(transform_content_to_ruby_rich_text, detail.get(\"例文\") or [])]\n",
    "\n",
    "        formatted_grammars.append({\n",
    "            \"id\": idx + 1,\n",
    "            \"content\": content,\n",
    "            \"hiragana\": hiragana,\n",
    "            \"meaning\": detail.get(\"说明\", \"\").strip(),\n",
    "            \"usage\": transform_content_to_ruby_rich_text(detail.get(\"接续\", \"\").strip()),\n",
    "            \"example\": formated_exmpale_sentences,\n",
    "            \"remark\": transform_content_to_ruby_rich_text(detail.get(\"注意\", \"\").strip()),\n",
    "            \"source\": \"S2N1-N5\",\n",
    "            \"japanese_meaning\": \"\",\n",
    "            \"chinese_meaning\": detail.get(\"说明\", \"\").strip(),\n",
    "            \"level\": detail[\"level\"]\n",
    "        })\n",
    "        if formatted_grammars[-1][\"usage\"] and formatted_grammars[-1][\"usage\"] != transform_content_to_ruby_rich_text(formatted_grammars[-1][\"usage\"]):\n",
    "            empty_usage.append(formatted_grammars[-1])\n",
    "    except Exception:\n",
    "        print(grammar)\n",
    "        print(content)\n",
    "        print(detail)\n",
    "        raise\n",
    "\n",
    "print(formatted_grammars[0])\n",
    "with open(\"grammars_N1-N5.json\", \"w\", encoding=\"utf-8\") as fp:\n",
    "    fp.write(json.dumps(formatted_grammars, ensure_ascii=False, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "名＋なりとも\n",
      "名＋なり 何 なん なりと\n",
      "名＋なりとも\n",
      "名＋なり<ruby>何<rt>なん</rt></ruby>なりと\n",
      "================================\n",
      "名词＋の/动词「た形」＋ 上 うえ で（の）\n",
      "名词＋の/动词「た形」＋<ruby>上<rt>うえ</rt></ruby>で（の）\n",
      "================================\n",
      "名词＋の/动词辞书形＋ 上 うえ で（は）/ 上 うえ での\n",
      "名词＋の/动词辞书形＋<ruby>上<rt>うえ</rt></ruby>で（は）/<ruby>上<rt>うえ</rt></ruby>での\n",
      "================================\n",
      "名词＋の/动词辞书形＋ 恐 おそ れがある\n",
      "名词＋の/动词辞书形＋<ruby>恐<rt>おそ</rt></ruby>れがある\n",
      "================================\n",
      "动词普通形/名词＋か 何 なに か\n",
      "动词普通形/名词＋か<ruby>何<rt>なに</rt></ruby>か\n",
      "================================\n",
      "名词＋から 言 い うと/から 言 い えば/から 言 い って\n",
      "名词＋から<ruby>言<rt>い</rt></ruby>うと/から<ruby>言<rt>い</rt></ruby>えば/から<ruby>言<rt>い</rt></ruby>って\n",
      "================================\n",
      "名词＋から 見 み ると/から 見 み れば/から 見 み て\n",
      "名词＋から<ruby>見<rt>み</rt></ruby>ると/から<ruby>見<rt>み</rt></ruby>れば/から<ruby>見<rt>み</rt></ruby>て\n",
      "================================\n",
      "名词＋の/动词「ている形」 ＋ 最 さい 中 ちゅう に\n",
      "名词＋の/动词「ている形」 ＋<ruby>最<rt>さい</rt></ruby><ruby>中<rt>ちゅう</rt></ruby>に\n",
      "================================\n",
      "名词＋ 上 じょう\n",
      "名词＋<ruby>上<rt>じょう</rt></ruby>\n",
      "================================\n",
      "① 名词＋って＋名词\n",
      "② 名词/句子的普通形＋って\n",
      "③ 句子的普通形＋って\n",
      "④ 句子的普通形+って+「 言 い う/ 思 おも う/ 書 か く/ 聞 き く」等\n",
      "① 名词＋って＋名词\n",
      "② 名词/句子的普通形＋って\n",
      "③ 句子的普通形＋って\n",
      "④ 句子的普通形+って+「<ruby>言<rt>い</rt></ruby>う/<ruby>思<rt>おも</rt></ruby>う/<ruby>書<rt>か</rt></ruby>く/<ruby>聞<rt>き</rt></ruby>く」等\n",
      "================================\n",
      "动词「て形」 ＋ 以 い 来 らい\n",
      "动词「て形」 ＋<ruby>以<rt>い</rt></ruby><ruby>来<rt>らい</rt></ruby>\n",
      "================================\n",
      "① ～によると/の 話 はなし では＋句子的普通形＋ということだ\n",
      "② 名词/动词普通形＋ということだ\n",
      "① ～によると/の<ruby>話<rt>はなし</rt></ruby>では＋句子的普通形＋ということだ\n",
      "② 名词/动词普通形＋ということだ\n",
      "================================\n",
      "动词「ます形」 ＋ 直 なお す\n",
      "动词「ます形」 ＋<ruby>直<rt>なお</rt></ruby>す\n",
      "================================\n",
      "名词＋に 関 かん して（は）/に 関 かん しても/に 関 かん する\n",
      "名词＋に<ruby>関<rt>かん</rt></ruby>して（は）/に<ruby>関<rt>かん</rt></ruby>しても/に<ruby>関<rt>かん</rt></ruby>する\n",
      "================================\n",
      "名词＋に 比 くら べ（て）/と 比 くら べ（て）\n",
      "名词＋に<ruby>比<rt>くら</rt></ruby>べ（て）/と<ruby>比<rt>くら</rt></ruby>べ（て）\n",
      "================================\n",
      "① 名词＋に 対 たい して/に 対 たい する\n",
      "② 名词＋に 対 たい して\n",
      "③ 动词普通形-の / い形容词普通形-の / な形容词词干-なの / 名词 ＋ に 対 たい して\n",
      "① 名词＋に<ruby>対<rt>たい</rt></ruby>して/に<ruby>対<rt>たい</rt></ruby>する\n",
      "② 名词＋に<ruby>対<rt>たい</rt></ruby>して\n",
      "③ 动词普通形-の / い形容词普通形-の / な形容词词干-なの / 名词 ＋ に<ruby>対<rt>たい</rt></ruby>して\n",
      "================================\n",
      "名词＋の 話 はなし では\n",
      "名词＋の<ruby>話<rt>はなし</rt></ruby>では\n",
      "================================\n",
      "名词＋ 向 む きだ/ 向 む きに/ 向 む きの\n",
      "名词＋<ruby>向<rt>む</rt></ruby>きだ/<ruby>向<rt>む</rt></ruby>きに/<ruby>向<rt>む</rt></ruby>きの\n",
      "================================\n",
      "名词＋ 向 む けだ/ 向 む けに/ 向 む けの\n",
      "名词＋<ruby>向<rt>む</rt></ruby>けだ/<ruby>向<rt>む</rt></ruby>けに/<ruby>向<rt>む</rt></ruby>けの\n",
      "================================\n",
      "名词＋を 込 こ めて\n",
      "名词＋を<ruby>込<rt>こ</rt></ruby>めて\n",
      "================================\n",
      "お＋Ⅰ类动词、Ⅱ类动词「ます形」 ＋ 願 ねが う\n",
      "ご＋Ⅲ类动词词干＋ 願 ねが う\n",
      "お＋Ⅰ类动词、Ⅱ类动词「ます形」 ＋<ruby>願<rt>ねが</rt></ruby>う\n",
      "ご＋Ⅲ类动词词干＋<ruby>願<rt>ねが</rt></ruby>う\n",
      "================================\n",
      "Ⅰ类动词「ない 形」 ＋せていただく\n",
      "Ⅱ类动词「ない 形」 ＋させていただく\n",
      "Ⅲ类动词：（～）する→（～）させていただく； 来 く る→ 来 こ させていただく\n",
      "Ⅰ类动词「ない 形」 ＋せていただく\n",
      "Ⅱ类动词「ない 形」 ＋させていただく\n",
      "Ⅲ类动词：（～）する→（～）させていただく；<ruby>来<rt>く</rt></ruby>る→<ruby>来<rt>こ</rt></ruby>させていただく\n",
      "================================\n",
      "Ⅰ类动词把词尾改为同行「え段」 假名＋る\n",
      "Ⅱ类动词「ない 形」 ＋られる\n",
      "Ⅲ类动词：（～）する→（～）できる； 来 く る→ 来 こ られる\n",
      "Ⅰ类动词把词尾改为同行「え段」 假名＋る\n",
      "Ⅱ类动词「ない 形」 ＋られる\n",
      "Ⅲ类动词：（～）する→（～）できる；<ruby>来<rt>く</rt></ruby>る→<ruby>来<rt>こ</rt></ruby>られる\n",
      "================================\n",
      "Ⅰ类动词「ない 形」 ＋せる\n",
      "Ⅱ类动词「ない 形」 ＋させる\n",
      "Ⅲ类动词：（～）する→（～）させる； 来 く る→ 来 こ させる\n",
      "Ⅰ类动词「ない 形」 ＋せる\n",
      "Ⅱ类动词「ない 形」 ＋させる\n",
      "Ⅲ类动词：（～）する→（～）させる；<ruby>来<rt>く</rt></ruby>る→<ruby>来<rt>こ</rt></ruby>させる\n",
      "================================\n",
      "Ⅰ类动词「ない 形」 ＋れる\n",
      "Ⅱ类动词「ない 形」 ＋られる\n",
      "Ⅲ类动词：（～）する→（～）される； 来 く る→ 来 こ られる\n",
      "Ⅰ类动词「ない 形」 ＋れる\n",
      "Ⅱ类动词「ない 形」 ＋られる\n",
      "Ⅲ类动词：（～）する→（～）される；<ruby>来<rt>く</rt></ruby>る→<ruby>来<rt>こ</rt></ruby>られる\n",
      "================================\n",
      "Ⅰ类动词「ない 形」 ＋される/せられる\n",
      "Ⅱ类动词「ない 形」 ＋させられる\n",
      "Ⅲ类动词：（～）する→（～）させられる； 来 く る→ 来 こ させられる\n",
      "Ⅰ类动词「ない 形」 ＋される/せられる\n",
      "Ⅱ类动词「ない 形」 ＋させられる\n",
      "Ⅲ类动词：（～）する→（～）させられる；<ruby>来<rt>く</rt></ruby>る→<ruby>来<rt>こ</rt></ruby>させられる\n",
      "================================\n",
      "Ⅰ类动词把词尾改为同行「え段」 假名\n",
      "Ⅱ类动词「ない 形」 ＋ろ\n",
      "Ⅲ类动词：（～）する→（～）しろ； 来 く る→ 来 こ い\n",
      "Ⅰ类动词把词尾改为同行「え段」 假名\n",
      "Ⅱ类动词「ない 形」 ＋ろ\n",
      "Ⅲ类动词：（～）する→（～）しろ；<ruby>来<rt>く</rt></ruby>る→<ruby>来<rt>こ</rt></ruby>い\n",
      "================================\n",
      "动词「ます形」＋ 方 か た\n",
      "动词「ます形」＋<ruby>方<rt>か</rt></ruby>た\n",
      "================================\n",
      "Ⅰ类动词把词尾改为同行「え段」 假名＋ば\n",
      "Ⅱ类动词「ない形」 ＋れば\n",
      "Ⅲ类动词：（～）する→（～）すれば； 来 く る→ 来 く れば\n",
      "い形容词词干＋ければ；名词＋であれば；な形容词词干＋であれば\n",
      "Ⅰ类动词把词尾改为同行「え段」 假名＋ば\n",
      "Ⅱ类动词「ない形」 ＋れば\n",
      "Ⅲ类动词：（～）する→（～）すれば；<ruby>来<rt>く</rt></ruby>る→<ruby>来<rt>く</rt></ruby>れば\n",
      "い形容词词干＋ければ；名词＋であれば；な形容词词干＋であれば\n",
      "================================\n",
      "动词意志形＋と 思 おも う\n",
      "动词意志形＋と<ruby>思<rt>おも</rt></ruby>う\n",
      "================================\n",
      "Ⅰ类动词「ない 形」 ＋せてください/せないでください\n",
      "Ⅱ类动词「ない 形」 ＋させてください/させないでください\n",
      "Ⅲ类动词：（～）する→（～）させてください/させないでください 来 く る→ 来 こ させてください/させないでください\n",
      "Ⅰ类动词「ない 形」 ＋せてください/せないでください\n",
      "Ⅱ类动词「ない 形」 ＋させてください/させないでください\n",
      "Ⅲ类动词：（～）する→（～）させてください/させないでください<ruby>来<rt>く</rt></ruby>る→<ruby>来<rt>こ</rt></ruby>させてください/させないでください\n",
      "================================\n",
      "Ⅰ类动词「ない 形」 ＋れる\n",
      "Ⅱ类动词「ない 形」 ＋られる\n",
      "Ⅲ类动词（～）する→（～）される； 来 く る→ 来 こ られる\n",
      "Ⅰ类动词「ない 形」 ＋れる\n",
      "Ⅱ类动词「ない 形」 ＋られる\n",
      "Ⅲ类动词（～）する→（～）される；<ruby>来<rt>く</rt></ruby>る→<ruby>来<rt>こ</rt></ruby>られる\n",
      "================================\n",
      "名词＋の/动词辞书形＋ 前 まえ に\n",
      "名词＋の/动词辞书形＋<ruby>前<rt>まえ</rt></ruby>に\n",
      "================================\n"
     ]
    }
   ],
   "source": [
    "for detail in empty_usage:\n",
    "    print(detail[\"usage\"])\n",
    "    print(transform_content_to_ruby_rich_text(detail[\"usage\"]))\n",
    "    print(\"=\" * 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 日语平假名unicode编码范围：\\u3040-\\u309F\n",
    "# 日语片假名unicode编码范围：\\u30A0-\\u30FF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = \"私の料理を一口食べるなり 、父は変な顔をして席を立ってしまった。\"\n",
    "get_md5(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from zipfile import ZipFile\n",
    "\n",
    "\n",
    "def extract_epub_images(epub_path, output_folder):\n",
    "    with ZipFile(epub_path, 'r') as epub_file:\n",
    "        for file_name in epub_file.namelist():\n",
    "            if file_name.endswith(('.jpg', '.jpeg', '.png', '.gif')):\n",
    "                output_file_path = os.path.join(output_folder, os.path.basename(file_name))\n",
    "                with open(output_file_path, 'wb') as output_file:\n",
    "                    output_file.write(epub_file.read(file_name))\n",
    "\n",
    "    print(\"Image extraction completed.\")\n",
    "\n",
    "\n",
    "# 示例用法\n",
    "epub_path = japanese_grammar.book_folder  / \"超值白金版.蓝宝书大全集：新日本语能力考试N1-N5文法详解（最新修订版） (许小明) (Z-Library).epub\" # 替换为实际的EPUB文件路径\n",
    "output_folder = japanese_grammar.book_folder / \"temp\"  # 替换为实际的输出文件夹路径\n",
    "\n",
    "extract_epub_images(epub_path, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fpdf import FPDF\n",
    "import os\n",
    "\n",
    "\n",
    "def merge_jpg_to_pdf(folder_path, output_path):\n",
    "    pdf = FPDF()\n",
    "\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith(\".jpg\"):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            pdf.add_page()\n",
    "            pdf.image(file_path, x=0, y=0, w=210)  # 设置图片大小为A4纸尺寸\n",
    "\n",
    "    pdf.output(output_path, \"F\")\n",
    "    print(\"PDF merging completed.\")\n",
    "\n",
    "\n",
    "# 示例用法\n",
    "folder_path = japanese_grammar.book_folder / \"temp\"  # 替换为实际的输出文件夹路径\n",
    "output_path = japanese_grammar.book_folder / \"file.pdf\"  # 替换为实际的输出文件夹路径\n",
    "\n",
    "merge_jpg_to_pdf(folder_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install fpdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import sys\n",
    "\n",
    "kana_meaning_pattern = re.compile(r\"^[△\\u2460-\\u2470\\s]*\")\n",
    "rich_text_pattern = re.compile(r\"<ruby>(.*?)<rt>.*?</rt></ruby>\")\n",
    "RE_WHITESPACES_PATTERN = re.compile(r\"\\s+\")\n",
    "\n",
    "with open(\"grammars_N1-N5.json\", \"r\", encoding=\"utf-8\") as fp:\n",
    "    formatted_grammars = json.loads(fp.read())\n",
    "\n",
    "total_sentence_amount = sum([len(grammar[\"example\"]) for grammar in formatted_grammars])\n",
    "print(f\"Total sentence amount: {total_sentence_amount}\")\n",
    "\n",
    "for grammar in tqdm(formatted_grammars, file=sys.stdout):\n",
    "    for sentence in grammar[\"example\"]:\n",
    "        content = sentence[\"content\"]\n",
    "        content = kana_meaning_pattern.sub(\"\", content)\n",
    "        content = rich_text_pattern.sub(r\"\\1\", content)\n",
    "        content = RE_WHITESPACES_PATTERN.sub(\"\", content)\n",
    "\n",
    "        content_md5 = get_md5(content)\n",
    "        audio_path = f\"japanese_grammar/audio/{content_md5}.mp3\"\n",
    "\n",
    "        text_to_audio.generate_audio([\n",
    "            (None, content),\n",
    "        ], audio_path, log=tqdm.write)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar_content_pattern = re.compile(r\"^\\d? ?[~\\u3040-\\u309F\\u30A0-\\u30FF\\u4E00-\\u9FFF  ()]+\")\n",
    "\n",
    "grammar_content_pattern.findall(\"~ 際 (に)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = \"ここに車を止められるのは、許可をもらっている人（a だけ　b に限り）です。\"\n",
    "content = re.sub(\"\\s+\", \" \", content)\n",
    "print(content)\n",
    "\n",
    "question_pattern = re.compile(r\"[（(](?:[\\da-n]\\s*[~\\u3040-\\u309F\\u30A0-\\u30FF\\u4E00-\\u9FFF]+\\s*)+[)）]\")\n",
    "print(question_pattern.findall(content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.findall(r\"(?:[\\da-n]\\s*[~\\u3040-\\u309F\\u30A0-\\u30FF\\u4E00-\\u9FFF]+\\s*)+\", \"a だけ b に限り\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_pattern = re.compile(r\"[(（](?:[\\da-n]\\s*[~\\u3040-\\u309F\\u30A0-\\u30FF\\u4E00-\\u9FFF]+\\s*)+[）)]*\\?\")\n",
    "print(question_pattern.findall(\"こちらの会議室をご利用になる際は、 受付で必要事項をご記入ください。\"))\n",
    "print(question_pattern.findall(\"ここに車を止められるのは、許可をもらっている人（a だけ　b に限り）です。\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "grammar_content_pattern = re.compile(r\"^\\d [~\\u3040-\\u309F\\u30A0-\\u30FF\\u4E00-\\u9FFF  ()]+\")\n",
    "sentence_content_pattern = re.compile(r'([\\u2460-\\u2470])\\s*')\n",
    "invalid_line_pattern = re.compile(r'^[\\d\\s]+$')\n",
    "\n",
    "example_sentences = []\n",
    "with open(\"CS_Word_20240403_23.41.17.txt\", \"r\", encoding=\"utf-8\") as fp:\n",
    "    matched = False\n",
    "    sentence = None\n",
    "    last_line = \"\"\n",
    "    for line in fp.readlines():\n",
    "        line = line.strip()\n",
    "        if len(line) < 3 or invalid_line_pattern.match(line.strip()):\n",
    "            continue\n",
    "\n",
    "        if grammar_content_pattern.match(line):\n",
    "            print(line)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
